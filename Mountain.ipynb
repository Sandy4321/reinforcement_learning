{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import keras\n",
    "from keras.initializers import VarianceScaling\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "import itertools\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(n_inputs, n_outputs, n_hidden=48, lr=0.001):\n",
    "    model = Sequential([\n",
    "        Dense(256, input_shape=(n_inputs,), activation=\"relu\", kernel_initializer='he_uniform'),\n",
    "        Dense(256, activation=\"relu\", kernel_initializer='he_uniform'),\n",
    "        #Dense(64, activation=\"relu\", kernel_initializer='he_uniform'),\n",
    "        Dense(n_outputs, activation=\"linear\")\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=RMSprop(lr=lr, clipvalue=1.0),\n",
    "                  loss=\"mse\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transfer_weights(model, learner, smooth=False):\n",
    "    if smooth:\n",
    "        tau = 0.125\n",
    "        weights = model.get_weights()\n",
    "        learner_weights = learner.get_weights()\n",
    "        for i in range(len(weights)):\n",
    "            weights[i] = learner_weights[i] * tau + weights[i] * (1 - tau)\n",
    "    else:\n",
    "        weights = learner.get_weights()\n",
    "    model.set_weights(weights)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def report_results(results, episode, episodes, solved, epsilon, rolling, prev_max, step_count):\n",
    "    best = np.max(results) if results else -1\n",
    "    rolling = rolling if rolling else [-1]\n",
    "    roll, variance = np.mean(rolling), np.var(rolling)\n",
    "    prev_max, best, roll, epsilon = [round(x, 3) for x in (prev_max, best, roll, epsilon)]\n",
    "    print(\"episodes: {}/{} - prev steps: {} - prev max: {} - global max: {} - rolling average: {} - epsilon: {}\".format(\n",
    "        episode, episodes, step_count, prev_max, best, roll, epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_learner(model, replay_buffer, gamma=0.95):\n",
    "    batchsize = 16\n",
    "    if len(replay_buffer) < batchsize:\n",
    "        return model\n",
    "    memory = np.array(replay_buffer)[np.random.choice(len(replay_buffer), batchsize, replace=False), :]\n",
    "    #priority1 = memory[memory[:, 0][0] > 0.5]\n",
    "    priority = memory[memory[:, 4] == True]\n",
    "    if len(priority) >= 2:\n",
    "        priority_sample = priority[np.random.choice(len(priority), 2, replace=False), :]\n",
    "        memory = np.concatenate([memory, priority])\n",
    "    X, y = np.zeros((len(memory), 2)), np.zeros((len(memory), 2))\n",
    "    for i, m in enumerate(memory):\n",
    "        state, action, reward, done, next_state = m[:2], int(m[2]), m[3], m[4], m[5:]\n",
    "        target = model.predict(state.reshape(-1, 2)).reshape(2)\n",
    "\n",
    "        if done:\n",
    "            total_reward = reward\n",
    "        else:\n",
    "            total_reward = reward + gamma * np.amax(model.predict(next_state.reshape(-1, 2)))\n",
    "        target[action] = total_reward\n",
    "        \n",
    "        X[i] = state.reshape(-1, 2)\n",
    "        y[i] = target.reshape(-1, 2)\n",
    "    \n",
    "    model.fit(X, y, epochs=1, verbose=0)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def play(model, learner, episodes=500, steps=200, epsilon=1.0, gamma=0.99, render=False):\n",
    "    env = gym.make(\"MountainCar-v0\")\n",
    "    results = []\n",
    "    rolling = deque(maxlen=8)\n",
    "    replay_buffer = deque(maxlen=100000)\n",
    "    highest, episode_max, step_count, n_solved = -1, -1, 0, 0\n",
    "    for episode in range(episodes):\n",
    "        state = env.reset()\n",
    "        report_results(results, episode, episodes, 0, epsilon, rolling, episode_max, step_count)\n",
    "        episode_memory = np.zeros((steps, 7))\n",
    "        episode_max = -1\n",
    "\n",
    "        for step in range(steps):\n",
    "            env.render() if render else None\n",
    "            if step % 1 == 0 and (np.random.random() < epsilon or step < 0):\n",
    "                action = np.random.randint(2)\n",
    "            elif step % 1 == 0:\n",
    "                action = np.argmax(model.predict(state.reshape(-1, 2)).flatten())\n",
    "            next_state, reward, done, _ = env.step(action * 2) # 0 for 0, 2 for 1\n",
    "            v0 = state[1]\n",
    "\n",
    "            episode_memory[step, :2] = state\n",
    "            episode_memory[step, 2] = action\n",
    "            episode_memory[step, 3] = reward\n",
    "            episode_memory[step, 4] = done\n",
    "            episode_memory[step, 5:] = next_state\n",
    "\n",
    "            replay_buffer.append(episode_memory[step])\n",
    "            state = next_state\n",
    "            \n",
    "            episode_max = np.max([episode_max, state[0]])\n",
    "            if state[0] > highest:\n",
    "                highest = state[0]\n",
    "            \n",
    "            learner = fit_learner(learner, replay_buffer, gamma)\n",
    "            \n",
    "            if done:\n",
    "                step_count = step\n",
    "                break\n",
    "        \n",
    "        rolling.append(episode_max)\n",
    "        results.append((highest, episode_max))\n",
    "        \n",
    "        model = transfer_weights(model, learner)\n",
    "        epsilon = np.max([epsilon - 0.005, 0.1])\n",
    "        \n",
    "        if step_count < 199:\n",
    "            n_solved += 1\n",
    "            print(\"solved ({}).\".format(n_solved))\n",
    "            if n_solved > 9:\n",
    "                return model, learner, results\n",
    "\n",
    "    return model, learner, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(2, 2)\n",
    "learner = build_model(2, 2)\n",
    "all_results = []\n",
    "model, learner, results = play(model, learner, episodes=250, epsilon=0.99, render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results.extend(results)\n",
    "global_max, episode_max = [r[0] for r in all_results], [r[1] for r in all_results]\n",
    "rolling = [np.mean(episode_max[i:i + 5]) for i in range(len(episode_max) - 10)]\n",
    "rolling.extend([np.mean(rolling) for _ in range(10)])\n",
    "l = range(len(global_max))\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 9)\n",
    "plt.plot(l, global_max)\n",
    "plt.plot(l, episode_max)\n",
    "plt.plot(l, rolling)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"MountainCar-v0\")\n",
    "s = env.reset()\n",
    "sm = 0\n",
    "d = False\n",
    "step = 0\n",
    "for i in range(10000):\n",
    "    if i % 1 == 0:\n",
    "        a = np.argmax(model.predict(s.reshape(-1, 2))) * 2\n",
    "    s, r, d, _ = env.step(a)\n",
    "    env.render()\n",
    "    if s[0] > 0.3 and s[0] > sm:\n",
    "        sm = s[0]\n",
    "        print(sm)\n",
    "    step += 1\n",
    "    if d:\n",
    "        s = env.reset()\n",
    "        if step < 199:\n",
    "            print(\"done in {} steps\".format(i))\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
